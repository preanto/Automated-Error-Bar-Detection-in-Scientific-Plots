{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQjpRvlqbOxJ",
        "outputId": "a67e6c71-e428-48a0-84fb-2c2c9b467694"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "jjuUZzRrEE2Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def detect_error_bar_endpoints(image_path, data_points_json):\n",
        "    \"\"\"\n",
        "    Detects upper and lower error bar endpoints for given data points.\n",
        "    Approach: Vertical Intensity Profiling along the x-coordinate. [cite: 27]\n",
        "    \"\"\"\n",
        "    # Load image in grayscale\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    # Thresholding: Convert dark error bars to white (255) on black (0)\n",
        "    # Synthetic plots usually have very clean white backgrounds (255)\n",
        "    _, thresh = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    output_error_bars = []\n",
        "\n",
        "    # Process each line/group [cite: 20]\n",
        "    for line in data_points_json.get(\"data_points\", []):\n",
        "        line_entry = {\"lineName\": line[\"lineName\"], \"points\": []}\n",
        "\n",
        "        for pt in line[\"points\"]:\n",
        "            x_orig, y_orig = pt[\"x\"], pt[\"y\"]\n",
        "            ix, iy = int(round(x_orig)), int(round(y_orig))\n",
        "\n",
        "            # Boundary constraints\n",
        "            h, w = thresh.shape\n",
        "            ix = max(0, min(ix, w - 1))\n",
        "            iy = max(0, min(iy, h - 1))\n",
        "\n",
        "            # --- Detect Upper Error Bar (Scan UP = Decreasing Y) --- [cite: 20]\n",
        "            upper_y = iy\n",
        "            # Check a 3px width to handle slight anti-aliasing or 1px shifts\n",
        "            while upper_y > 0:\n",
        "                roi = thresh[upper_y - 1, max(0, ix-1):min(w, ix+2)]\n",
        "                if np.any(roi == 255):\n",
        "                    upper_y -= 1\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            # --- Detect Lower Error Bar (Scan DOWN = Increasing Y) --- [cite: 20]\n",
        "            lower_y = iy\n",
        "            while lower_y < h - 1:\n",
        "                roi = thresh[lower_y + 1, max(0, ix-1):min(w, ix+2)]\n",
        "                if np.any(roi == 255):\n",
        "                    lower_y += 1\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            # Append in the mandatory output format\n",
        "            line_entry[\"points\"].append({\n",
        "                \"data_point\": {\"x\": x_orig, \"y\": y_orig},\n",
        "                \"upper_error_bar\": {\"x\": x_orig, \"y\": float(upper_y)},\n",
        "                \"lower_error_bar\": {\"x\": x_orig, \"y\": float(lower_y)}\n",
        "            })\n",
        "\n",
        "        output_error_bars.append(line_entry)\n",
        "\n",
        "    return output_error_bars\n",
        "\n",
        "# --- CONFIGURATION --- [cite: 6]\n",
        "# Update these paths to match your Google Drive folder structure\n",
        "BASE_PATH = '/content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2'\n",
        "IMAGES_DIR = os.path.join(BASE_PATH, 'images')\n",
        "LABELS_DIR = os.path.join(BASE_PATH, 'labels')\n",
        "RESULTS_DIR = os.path.join(BASE_PATH, 'detection_results')\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# --- EXECUTION LOOP --- [cite: 17]\n",
        "label_files = [f for f in os.listdir(LABELS_DIR) if f.endswith('.json')]\n",
        "print(f\"Processing {len(label_files)} files...\")\n",
        "\n",
        "for filename in tqdm(label_files):\n",
        "    try:\n",
        "        with open(os.path.join(LABELS_DIR, filename), 'r') as f:\n",
        "            input_data = json.load(f)\n",
        "\n",
        "        image_name = input_data[\"image_file\"]\n",
        "        image_path = os.path.join(IMAGES_DIR, image_name)\n",
        "\n",
        "        # Run detection pipeline [cite: 19]\n",
        "        detected_data = detect_error_bar_endpoints(image_path, input_data)\n",
        "\n",
        "        if detected_data:\n",
        "            # Construct final JSON object\n",
        "            final_output = {\n",
        "                \"image_file\": image_name,\n",
        "                \"error_bars\": detected_data\n",
        "            }\n",
        "\n",
        "            # Save the result to Google Drive [cite: 31, 34]\n",
        "            with open(os.path.join(RESULTS_DIR, filename), 'w') as f:\n",
        "                json.dump(final_output, f, indent=2)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in {filename}: {e}\")\n",
        "\n",
        "print(f\"Pipeline finished. Results saved to {RESULTS_DIR}\")"
      ],
      "metadata": {
        "id": "wLhg40h2cR_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50598bcd-45a7-4c87-c107-0b6dba699c9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 3001 files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3001/3001 [23:45<00:00,  2.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline finished. Results saved to /content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2/detection_results\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Path to detection results from Assignment 2 [cite: 22, 45]\n",
        "RESULTS_DIR = '/content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2/detection_results'\n",
        "# Path to original labels containing true distances (from Assignment 1) [cite: 5, 11]\n",
        "GROUND_TRUTH_DIR = '/content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2/labels'\n",
        "\n",
        "def evaluate_performance(pixel_tolerance=2.0):\n",
        "    \"\"\"\n",
        "    Calculates MAE and Accuracy based on pixel distance.\n",
        "    \"\"\"\n",
        "    result_files = [f for f in os.listdir(RESULTS_DIR) if f.endswith('.json')]\n",
        "\n",
        "    total_y_error = 0\n",
        "    total_points = 0\n",
        "    successful_detections = 0\n",
        "\n",
        "    print(f\"Evaluating {len(result_files)} files...\")\n",
        "\n",
        "    for filename in tqdm(result_files):\n",
        "        try:\n",
        "            with open(os.path.join(RESULTS_DIR, filename), 'r') as f:\n",
        "                det = json.load(f)\n",
        "            with open(os.path.join(GROUND_TRUTH_DIR, filename), 'r') as f:\n",
        "                tru = json.load(f)\n",
        "\n",
        "            # Compare detected endpoints vs ground truth distances\n",
        "            # This logic assumes 'tru' has 'topBarPixelDistance' or 'upper_error_bar'\n",
        "            for d_line, t_line in zip(det['error_bars'], tru['data_points']):\n",
        "                for d_p, t_p in zip(d_line['points'], t_line['points']):\n",
        "                    # Calculate Detected Distances\n",
        "                    det_top = abs(d_p['upper_error_bar']['y'] - d_p['data_point']['y'])\n",
        "                    det_bot = abs(d_p['lower_error_bar']['y'] - d_p['data_point']['y'])\n",
        "\n",
        "                    # Truth Distances (Fallback logic if keys differ)\n",
        "                    true_top = t_p.get('topBarPixelDistance', 0)\n",
        "                    true_bot = t_p.get('bottomBarPixelDistance', 0)\n",
        "\n",
        "                    # Accumulate Error\n",
        "                    top_err = abs(det_top - true_top)\n",
        "                    bot_err = abs(det_bot - true_bot)\n",
        "\n",
        "                    total_y_error += (top_err + bot_err)\n",
        "                    total_points += 2\n",
        "\n",
        "                    # Accuracy check within tolerance\n",
        "                    if top_err <= pixel_tolerance: successful_detections += 1\n",
        "                    if bot_err <= pixel_tolerance: successful_detections += 1\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if total_points == 0:\n",
        "        print(\"\\n[!] Error: No points matched. Check if your ground truth labels contain distances.\")\n",
        "        return\n",
        "\n",
        "    mae = total_y_error / total_points\n",
        "    accuracy = (successful_detections / total_points) * 100\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(f\"QUANTITATIVE EVALUATION RESULTS\")\n",
        "    print(\"=\"*30)\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.4f} pixels\")\n",
        "    print(f\"Accuracy (±{pixel_tolerance}px): {accuracy:.2f}%\")\n",
        "    print(f\"Total Points Evaluated: {total_points}\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "evaluate_performance()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgDLY-KMp4qT",
        "outputId": "1fd98c5d-28e0-43ad-90f9-8dd98434f6d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating 3001 files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3001/3001 [23:19<00:00,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "QUANTITATIVE EVALUATION RESULTS\n",
            "==============================\n",
            "Mean Absolute Error (MAE): 21.9764 pixels\n",
            "Accuracy (±2.0px): 35.63%\n",
            "Total Points Evaluated: 112000\n",
            "==============================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Path to the source images from Assignment 1\n",
        "IMAGE_DIR = '/content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2/detection_results'\n",
        "# Path to the results JSONs from Assignment 2 pipeline [cite: 22, 45]\n",
        "RESULTS_DIR = '/content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2/detection_results'\n",
        "# Output directory for the final verified images [cite: 38]\n",
        "VIS_OUT_DIR = '/content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2/visualization'\n",
        "\n",
        "os.makedirs(VIS_OUT_DIR, exist_ok=True)\n",
        "\n",
        "def visualize_full_dataset():\n",
        "    \"\"\"\n",
        "    Overlays detected error bars onto images for the entire 3000-image set.\n",
        "    \"\"\"\n",
        "    # Get all result files\n",
        "    result_files = [f for f in os.listdir(RESULTS_DIR) if f.endswith('.json')]\n",
        "\n",
        "    if not result_files:\n",
        "        print(f\"No results found in {RESULTS_DIR}. Please check your paths.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Starting visualization for {len(result_files)} images...\")\n",
        "\n",
        "    for filename in tqdm(result_files):\n",
        "        try:\n",
        "            # Load the detection result [cite: 22]\n",
        "            with open(os.path.join(RESULTS_DIR, filename), 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Load corresponding plot image [cite: 21]\n",
        "            img_path = os.path.join(IMAGE_DIR, data['image_file'])\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Iterate through each detected line and its points [cite: 20]\n",
        "            for line in data['error_bars']:\n",
        "                for pt in line['points']:\n",
        "                    # Extract coordinates [cite: 20]\n",
        "                    # Data Point (Input from Assignment 2) [cite: 21]\n",
        "                    x_c = int(round(pt['data_point']['x']))\n",
        "                    y_c = int(round(pt['data_point']['y']))\n",
        "\n",
        "                    # Detected Endpoints (Output from your Pipeline) [cite: 22]\n",
        "                    y_u = int(round(pt['upper_error_bar']['y']))\n",
        "                    y_l = int(round(pt['lower_error_bar']['y']))\n",
        "\n",
        "                    # DRAWING LOGIC:\n",
        "                    # 1. Draw the error bar vertical line (Green)\n",
        "                    cv2.line(img, (x_c, y_u), (x_c, y_l), (0, 255, 0), 1)\n",
        "\n",
        "                    # 2. Draw the data point center (Blue)\n",
        "                    cv2.circle(img, (x_c, y_c), 3, (255, 0, 0), -1)\n",
        "\n",
        "                    # 3. Draw the detected endpoints (Red)\n",
        "                    cv2.circle(img, (x_c, y_u), 3, (0, 0, 255), -1)\n",
        "                    cv2.circle(img, (x_c, y_l), 3, (0, 0, 255), -1)\n",
        "\n",
        "            # Save to the verification folder [cite: 38]\n",
        "            save_name = f\"vis_{data['image_file']}\"\n",
        "            cv2.imwrite(os.path.join(VIS_OUT_DIR, save_name), img)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {filename} due to error: {e}\")\n",
        "\n",
        "    print(f\"\\nSuccessfully generated {len(os.listdir(VIS_OUT_DIR))} visualizations.\")\n",
        "    print(f\"Results located at: {VIS_OUT_DIR}\")\n",
        "\n",
        "# Run the full visualization\n",
        "visualize_full_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA40FIeWLntA",
        "outputId": "f1eb0888-6ffb-46a5-b762-59a66904e34b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Starting visualization for 3001 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3001/3001 [00:50<00:00, 59.61it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Successfully generated 50 visualizations.\n",
            "Results located at: /content/drive/MyDrive/Datasets/Delinate Assessment/Synthetic-Dataset-V2/visualization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ssKb_dllL92T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}